#include <stdio.h>
#include <unistd.h>
#include <vector>
#include <mutex>
#include <string>

#include "tasks.h"
#include "queue_helper.h"
#include "lcd_driver.h"
#include "config.h"
#include "facenet.h" 
//T·ªïng quan h·ªá th·ªëng 3 task ch·∫°y song song
// --- D·ªÆ LI·ªÜU CHIA S·∫∫ (SHARED DATA) ---

// Struct l∆∞u k·∫øt qu·∫£ nh·∫≠n di·ªán ƒë·ªÉ lu·ªìng LCD v·∫Ω

struct AIResult {
    std::vector<cv::Rect> faces;
    std::string message;
    cv::Scalar color;
    bool has_detection;
};

// Bi·∫øn to√†n c·ª•c v√† Mutex b·∫£o v·ªá
// Bi·∫øn to√†n c·ª•c v√† Mutex b·∫£o v·ªá
std::mutex mtx_ai;              // Kh√≥a an to√†n
cv::Mat shared_ai_frame;        // Frame m·ªõi nh·∫•t ƒë·ªÉ AI x·ª≠ l√Ω
bool new_frame_for_ai = false;  // C·ªù b√°o c√≥ ·∫£nh m·ªõi
AIResult shared_result;         // K·∫øt qu·∫£ AI ƒë·ªÉ LCD hi·ªÉn th·ªã

// ƒê·ªëi t∆∞·ª£ng FaceNet v√† bi·∫øn l∆∞u ch·ªß nh√¢n
// L∆∞u tr·ªØ nhi·ªÅu embeddings cho vi·ªác ƒëƒÉng k√Ω
std::vector<cv::Mat> owner_face_samples;  // L∆∞u ·∫£nh m·∫´u
FaceNet faceNet;
cv::Mat owner_embedding;
bool has_owner = false;
const int REQUIRED_SAMPLES = 10;           // C·∫ßn 15 m·∫´u t·ªët ƒë·ªÉ ƒëƒÉng k√Ω
const int MIN_FRAME_GAP = 15;             // Ch·ªù 15 frame gi·ªØa c√°c m·∫´u
int frame_counter_since_last_sample = 0;  // ƒê·∫øm frame

// Th·ªëng k√™ ƒë·ªÉ debug
struct RegistrationStats {
    std::vector<float> quality_scores;
    std::vector<float> similarities;  // So s√°nh gi·ªØa c√°c m·∫´u
    
    void addSample(float quality) {
        quality_scores.push_back(quality);
    }
    
    void printStats() {
        if (quality_scores.empty()) return;
        
        float avg_quality = 0;
        for (float q : quality_scores) avg_quality += q;
        avg_quality /= quality_scores.size();
        
        printf("\n=== REGISTRATION STATS ===\n");
        printf("Samples collected: %zu\n", quality_scores.size());
        printf("Average quality: %.2f\n", avg_quality);
        
        if (!similarities.empty()) {
            float avg_sim = 0;
            for (float s : similarities) avg_sim += s;
            avg_sim /= similarities.size();
            printf("Avg inter-sample similarity: %.3f\n", avg_sim);
        }
        printf("==========================\n\n");
    }
    
    void clear() {
        quality_scores.clear();
        similarities.clear();
    }
};

RegistrationStats reg_stats;

// B·ªô l·ªçc k·∫øt qu·∫£
struct DetectionFilter {
    std::vector<float> recent_similarities;
    const int WINDOW_SIZE = 7;  // TƒÉng l√™n 7 frame
    
    bool isStable(float new_similarity) {
        recent_similarities.push_back(new_similarity);
        if (recent_similarities.size() > (size_t)WINDOW_SIZE) {
            recent_similarities.erase(recent_similarities.begin());
        }
        
        if (recent_similarities.size() < 5) return false;
        
        // T√≠nh ƒë·ªô l·ªách chu·∫©n
        float mean = 0;
        for (float s : recent_similarities) mean += s;
        mean /= recent_similarities.size();
        
        float variance = 0;
        for (float s : recent_similarities) {
            variance += (s - mean) * (s - mean);
        }
        variance /= recent_similarities.size();
        float stddev = sqrt(variance);
        
        // ·ªîn ƒë·ªãnh n·∫øu stddev < 0.05
        return stddev < 0.05f;
    }
    
    float getAverage() {
        if (recent_similarities.empty()) return 0.0f;
        float sum = 0;
        for (float s : recent_similarities) sum += s;
        return sum / recent_similarities.size();
    }
    
    void clear() {
        recent_similarities.clear();
    }
};

DetectionFilter detection_filter;

// === H√ÄM H·ªñ TR·ª¢ C·∫¢I TI·∫æN ===

bool isFaceAligned(const cv::Rect& face, const cv::Mat& frame) {
    float aspect_ratio = (float)face.width / face.height;
    if (aspect_ratio < 0.75f || aspect_ratio > 1.25f) return false;
    
    int margin = 30;
    if (face.x < margin || face.y < margin ||
        face.x + face.width > frame.cols - margin ||
        face.y + face.height > frame.rows - margin) {
        return false;
    }
    
    if (face.width < 80 || face.height < 80) return false;
    
    return true;
}

cv::Rect selectBestFace(const std::vector<cv::Rect>& faces, 
                         const cv::Mat& frame,
                         FaceNet& faceNet) {
    if (faces.empty()) return cv::Rect();
    
    float best_score = -1.0f;
    cv::Rect best_face;
    
    for (const auto& face : faces) {
        if (!isFaceAligned(face, frame)) continue;
        
        cv::Mat face_roi = frame(face);
        float quality = faceNet.checkQuality(face_roi);
        float size_score = std::min(1.0f, (face.width * face.height) / 12000.0f);
        
        float total_score = quality * 0.8f + size_score * 0.2f;
        
        if (total_score > best_score) {
            best_score = total_score;
            best_face = face;
        }
    }
    
    return best_face;
}

// Ki·ªÉm tra m·∫´u c√≥ ƒë·ªß kh√°c bi·ªát kh√¥ng
bool isSampleDiverse(const cv::Mat& new_sample, FaceNet& faceNet) {
    if (owner_face_samples.size() < 2) return true;
    
    cv::Mat new_emb = faceNet.getEmbedding(new_sample);
    if (new_emb.empty()) return false;
    
    // So s√°nh v·ªõi m·∫´u cu·ªëi c√πng
    cv::Mat last_sample = owner_face_samples.back();
    cv::Mat last_emb = faceNet.getEmbedding(last_sample);
    
    if (last_emb.empty()) return false;
    
    float similarity = faceNet.cosineSimilarity(new_emb, last_emb);
    reg_stats.similarities.push_back(similarity);
    
    // N·∫øu qu√° gi·ªëng (>0.95) th√¨ t·ª´ ch·ªëi
    if (similarity > 0.95f) {
        printf("[Diversity Check] Too similar (%.3f) - REJECTED\n", similarity);
        return false;
    }
    
    printf("[Diversity Check] Similarity: %.3f - OK\n", similarity);
    return true;
}



// --- TASK 1: CAMERA (PRODUCER) ---
//Camera Thread  -->  ƒë∆∞a ·∫£nh v√†o Queue
/*Nhi·ªám v·ª•:
‚úî M·ªü camera
‚úî L·∫•y frame li√™n t·ª•c
‚úî ƒê·∫©y frame v√†o queue hi·ªÉn th·ªã
‚úî G·ª≠i frame cho AI x·ª≠ l√Ω (shared frame)*/
void* task_camera(void* arg) {
    // M·ªü Camera (∆Øu ti√™n V4L2 tr√™n Linux/Pi)
    cv::VideoCapture cap(0, cv::CAP_V4L2);

    // C·∫•u h√¨nh c·ª©ng ƒë·ªô ph√¢n gi·∫£i kh·ªõp v·ªõi LCD ƒë·ªÉ kh√¥ng ph·∫£i resize
    cap.set(cv::CAP_PROP_FRAME_WIDTH, LCD_WIDTH);  // 320
    cap.set(cv::CAP_PROP_FRAME_HEIGHT, LCD_HEIGHT); // 240
    cap.set(cv::CAP_PROP_FPS, 30);


    if (!cap.isOpened()) {
        printf("[Task Cam] Error: Cannot open camera! Check connection.\n");
        return NULL;
    }

    cv::Mat cam_frame;
    cv::Mat frame;
    printf("[Task Cam] Started successfully\n");

    while(1) {
        cap >> cam_frame;
        cv::resize(cam_frame, frame, cv::Size(LCD_WIDTH, LCD_HEIGHT));   
        if (frame.empty()) {
            usleep(10000);
            continue;
        }

        // 1. ƒê·∫©y v√†o h√†ng ƒë·ª£i hi·ªÉn th·ªã (Queue Display)
        // Clone() l√† b·∫Øt bu·ªôc ƒë·ªÉ tr√°nh xung ƒë·ªôt v√πng nh·ªõ
        queue_push(&q_display, frame.clone());

        // 2. C·∫≠p nh·∫≠t frame cho AI (Ghi ƒë√® frame c≈© n·∫øu AI ch∆∞a x·ª≠ l√Ω k·ªãp)
        {
            std::lock_guard<std::mutex> lock(mtx_ai);
            shared_ai_frame = frame.clone();
            new_frame_for_ai = true;
        }

        // Ng·ªß nh·∫π ƒë·ªÉ gi·∫£m t·∫£i CPU n·∫øu c·∫ßn (t√πy ch·ªçn)
        usleep(1000); 
    }
    return NULL;
}


// --- TASK 2: AI PROCESSING (BACKGROUND) ---
//AI Thread -->  ƒë·ªçc shared frame -> detect face -> embed -> compare
/*Nhi·ªám v·ª•:
1Ô∏è‚É£ Load model MobileFaceNet
2Ô∏è‚É£ Load Haar cascade ƒë·ªÉ detect face
3Ô∏è‚É£ L·∫•y frame t·ª´ thread Camera
üîç AI x·ª≠ l√Ω g·ªìm 3 b∆∞·ªõc l·ªõn
B∆∞·ªõc A: Detect Face
B∆∞·ªõc B: L·∫•y embedding t·ª´ khu√¥n m·∫∑t l·ªõn nh·∫•t
B∆∞·ªõc C: So s√°nh embedding ƒë·ªÉ nh·∫≠n di·ªán
N·∫øu ch∆∞a c√≥ ch·ªß nh√¢n (has_owner = false)
N·∫øu ƒë√£ c√≥ ch·ªß nh√¢n ‚Üí So s√°nh cosine distance
4Ô∏è‚É£ C·∫≠p nh·∫≠t k·∫øt qu·∫£ cho LCD
*/
// === TASK AI N√ÇNG C·∫§P ===
// === TASK AI FINAL VERSION ===

void* task_ai_improved(void* arg) {
    printf("[Task AI] Loading Models...\n");
    
    // Load Model
    try {
        faceNet.loadModel("MobileFaceNet.onnx");
        if (!faceNet.isLoaded()) {
            printf("[Task AI] CRITICAL: Model load failed!\n");
            return NULL;
        }
    } catch (const cv::Exception& e) {
        printf("[Task AI] Error: %s\n", e.what());
        return NULL;
    }
    
    // Load Haar Cascade
    cv::CascadeClassifier face_cascade;
    if(!face_cascade.load("/home/pi/opencv/data/haarcascades/haarcascade_frontalface_default.xml")) {
        if(!face_cascade.load("haarcascade_frontalface_default.xml")) {
            printf("[Task AI] Error: Cannot load cascade!\n");
            return NULL;
        }
    }

    cv::Mat process_frame;
    printf("[Task AI] ===== FINAL VERSION LOADED =====\n");
    printf("[Task AI] Using: Cosine Similarity | Augmentation | Diversity Check\n\n");

    while(1) {
        bool has_new = false;

        // L·∫•y frame
        {
            std::lock_guard<std::mutex> lock(mtx_ai);
            if (new_frame_for_ai) {
                process_frame = shared_ai_frame.clone();
                new_frame_for_ai = false;
                has_new = true;
            }
        }

        if (!has_new) {
            usleep(10000);
            continue;
        }

        frame_counter_since_last_sample++;

        // === X·ª¨ L√ù AI ===
        AIResult local_result;
        local_result.has_detection = false;
        local_result.message = "Scanning...";
        local_result.color = cv::Scalar(0, 255, 255);
        
        // Detect faces
        std::vector<cv::Rect> faces;
        cv::Mat gray;
        cv::cvtColor(process_frame, gray, cv::COLOR_BGR2GRAY);
        
        face_cascade.detectMultiScale(
            gray, faces,
            1.05, 5, 0,
            cv::Size(60, 60),
            cv::Size(240, 240)
        );

        if (!faces.empty()) {
            cv::Rect best_face = selectBestFace(faces, process_frame, faceNet);
            
            if (best_face.area() > 0) {
                local_result.has_detection = true;
                local_result.faces.push_back(best_face);
                
                cv::Mat face_roi = process_frame(best_face);
                float quality = faceNet.checkQuality(face_roi);
                
                // === ƒêƒÇNG K√ù CH·ª¶ NH√ÇN ===
                if (!has_owner) {
                    // Y√™u c·∫ßu: Quality cao + ƒê·ª£i ƒë·ªß frame gap + ƒêa d·∫°ng
                    if (quality > 0.55f && frame_counter_since_last_sample >= MIN_FRAME_GAP) {
                        
                        // Ki·ªÉm tra ƒë·ªô ƒëa d·∫°ng
                        if (isSampleDiverse(face_roi, faceNet)) {
                            owner_face_samples.push_back(face_roi.clone());
                            reg_stats.addSample(quality);
                            frame_counter_since_last_sample = 0;
                            
                            int progress = (owner_face_samples.size() * 100) / REQUIRED_SAMPLES;
                            local_result.message = "Register: " + std::to_string(progress) + "%";
                            local_result.color = cv::Scalar(255, 200, 0);
                            
                            printf("[Register] Sample %zu/%d | Q: %.2f | Gap: OK\n", 
                                   owner_face_samples.size(), REQUIRED_SAMPLES, quality);
                            
                            // ƒê·ªß m·∫´u
                            if (owner_face_samples.size() >= REQUIRED_SAMPLES) {
                                printf("\n[Register] Processing samples...\n");
                                owner_embedding = faceNet.registerOwner(owner_face_samples);
                                
                                if (!owner_embedding.empty()) {
                                    has_owner = true;
                                    local_result.message = "REGISTRATION COMPLETE!";
                                    local_result.color = cv::Scalar(0, 255, 0);
                                    
                                    reg_stats.printStats();
                                    printf("[Register] ==> SUCCESS <==\n\n");
                                } else {
                                    printf("[Register] Failed! Retrying...\n");
                                    owner_face_samples.clear();
                                    reg_stats.clear();
                                    frame_counter_since_last_sample = 0;
                                }
                            }
                        } else {
                            local_result.message = "Move your head slightly";
                            local_result.color = cv::Scalar(255, 150, 0);
                        }
                    } else {
                        if (quality <= 0.55f) {
                            local_result.message = "Low Quality (Q:" + 
                                                  std::to_string((int)(quality*100)) + ")";
                        } else {
                            int frames_left = MIN_FRAME_GAP - frame_counter_since_last_sample;
                            local_result.message = "Wait " + std::to_string(frames_left) + " frames";
                        }
                        local_result.color = cv::Scalar(100, 100, 255);
                    }
                }
                // === NH·∫¨N DI·ªÜN ===
                else {
                    if (quality > 0.45f) {
                        cv::Mat current_embedding = faceNet.getEmbedding(face_roi);
                        
                        if (!current_embedding.empty()) {
                            float similarity = faceNet.cosineSimilarity(
                                current_embedding, 
                                owner_embedding
                            );
                            
                            // L·ªçc ·ªïn ƒë·ªãnh
                            bool is_stable = detection_filter.isStable(similarity);
                            float avg_similarity = detection_filter.getAverage();
                            
                            // QUAN TR·ªåNG: Threshold cao h∆°n cho Cosine Similarity
                            const float THRESHOLD = 0.90f;  // >= 0.90 = c√πng ng∆∞·ªùi
                            
                            if (is_stable) {
                                if (avg_similarity >= THRESHOLD) {
                                    local_result.message = "ACCESS GRANTED";
                                    local_result.color = cv::Scalar(0, 255, 0);
                                    printf("[VERIFY] ‚úì OWNER (Sim: %.3f)\n", avg_similarity);
                                } else {
                                    local_result.message = "ACCESS DENIED";
                                    local_result.color = cv::Scalar(0, 0, 255);
                                    printf("[VERIFY] ‚úó UNKNOWN (Sim: %.3f)\n", avg_similarity);
                                }
                            } else {
                                local_result.message = "Analyzing... (" + 
                                                      std::to_string((int)(similarity*100)) + "%)";
                                local_result.color = cv::Scalar(200, 200, 0);
                            }
                        }
                    } else {
                        local_result.message = "Move closer (Q:" + 
                                              std::to_string((int)(quality*100)) + ")";
                        local_result.color = cv::Scalar(150, 150, 150);
                    }
                }
            }
        } else {
            local_result.message = "No Face";
            detection_filter.clear();
            frame_counter_since_last_sample = 0;
        }

        // C·∫≠p nh·∫≠t k·∫øt qu·∫£
        {
            std::lock_guard<std::mutex> lock(mtx_ai);
            shared_result = local_result;
        }
        
        usleep(5000);
    }
    return NULL;
}

// --- TASK 3: LCD DISPLAY (CONSUMER) ---
//LCD Thread -->  l·∫•y frame t·ª´ Queue -> v·∫Ω UI -> convert RGB -> ƒë·∫©y ra LCD SPI
//LCD s·∫Ω l·∫•y k·∫øt qu·∫£ c·ªßa AI t·ª´ ƒë√¢y ƒë·ªÉ v·∫Ω.
/*Nhi·ªám v·ª•:
‚úî L·∫•y frame t·ª´ queue
‚úî V·∫Ω bounding box + message c·ªßa AI
‚úî Convert BGR ‚Üí RGB565
‚úî G·ª≠i frame qua SPI cho LCD*/
void* task_lcd(void* arg) {
    // C·∫•p ph√°t buffer SPI 1 l·∫ßn duy nh·∫•t
    uint8_t* spi_buffer = (uint8_t*)malloc(LCD_WIDTH * LCD_HEIGHT * 2);
    if (!spi_buffer) {
        printf("[Task LCD] Malloc failed!\n");
        return NULL;
    }

    cv::Mat frame;
    AIResult current_ai_state;
    printf("[Task LCD] Started\n");
    
    while(1) {
        // L·∫•y frame t·ª´ h√†ng ƒë·ª£i (Blocking wait -> Ti·∫øt ki·ªám CPU khi kh√¥ng c√≥ ·∫£nh)
        queue_pop(&q_display, &frame);
        
        // 1. Resize n·∫øu k√≠ch th∆∞·ªõc camera kh√¥ng kh·ªõp LCD
        if (frame.cols != LCD_WIDTH || frame.rows != LCD_HEIGHT) {
            cv::resize(frame, frame, cv::Size(LCD_WIDTH, LCD_HEIGHT));
        }

        // 2. L·∫•y th√¥ng tin AI m·ªõi nh·∫•t
        {
            std::lock_guard<std::mutex> lock(mtx_ai);
            current_ai_state = shared_result;
        }

        // 3. V·∫Ω UI l√™n ·∫£nh (V·∫Ω TR∆Ø·ªöC khi convert m√†u)
        if (current_ai_state.has_detection) {
            for (size_t i = 0; i < current_ai_state.faces.size(); i++) {
                cv::rectangle(frame, current_ai_state.faces[i], current_ai_state.color, 2);
            }
            // V·∫Ω ch·ªØ
            if (!current_ai_state.faces.empty()) {
                cv::Point p = current_ai_state.faces[0].tl();
                p.y = (p.y < 20) ? 20 : p.y - 10;
                cv::putText(frame, current_ai_state.message, p, 
                            cv::FONT_HERSHEY_SIMPLEX, 0.6, current_ai_state.color, 2);
            }
        } else {
             // Hi·ªÉn th·ªã tr·∫°ng th√°i ch·ªù ·ªü g√≥c
             cv::putText(frame, "Waiting...", cv::Point(5, 20), 
                        cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(200, 200, 200), 1);
        }

        // 4. Chuy·ªÉn ƒë·ªïi BGR sang RGB565 (T·ªëi ∆∞u h√≥a v√≤ng l·∫∑p)
        int idx = 0;
        uint8_t* data = frame.data;
        int channels = frame.channels(); // 3
        int width = frame.cols;
        int height = frame.rows;

        for (int i = 0; i < height; i++) {
            // T·ªëi ∆∞u h√≥a: T√≠nh index d√≤ng tr∆∞·ªõc
            int row_offset = i * width * channels;
            
            for (int j = 0; j < width; j++) {
                int pixel_idx = row_offset + (j * channels);
                
                uint8_t b = data[pixel_idx + 0];
                uint8_t g = data[pixel_idx + 1];
                uint8_t r = data[pixel_idx + 2];
                
                // RGB565 conversion
                uint16_t c = ((r & 0xF8) << 8) | ((g & 0xFC) << 3) | (b >> 3);
                
                // Big Endian cho SPI
                spi_buffer[idx++] = (c >> 8) & 0xFF;
                spi_buffer[idx++] = c & 0xFF;
            }
        }
        
        // 5. G·ª≠i ra LCD qua SPI
        bcm2835_gpio_write(PIN_DC, LOW); // Command mode
        lcd_set_window(0, 0, LCD_WIDTH-1, LCD_HEIGHT-1); 
        
        bcm2835_gpio_write(PIN_DC, HIGH); // Data mode
        bcm2835_spi_transfern((char*)spi_buffer, LCD_WIDTH * LCD_HEIGHT * 2);
    }
    
    free(spi_buffer);
    return NULL;
}



    

